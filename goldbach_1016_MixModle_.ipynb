{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOdDKImMIW5A1GQjcxIPfUa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bread806/goldbach_backup_from_colab/blob/main/goldbach_1016_MixModle_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/Drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9qnR_PN5EFK",
        "outputId": "70d20988-f40e-4eb9-e16b-ef2448ad3ac7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "def is_prime(num):\n",
        "    \"\"\"檢查一個數字是否為質數\"\"\"\n",
        "    if num <= 1:\n",
        "        return False\n",
        "    for i in range(2, int(num ** 0.5) + 1):\n",
        "        if num % i == 0:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def prime_table(x):\n",
        "    \"\"\"建立小於x的質數表\"\"\"\n",
        "    primes = [num for num in range(2, x) if is_prime(num)]\n",
        "    return primes\n",
        "\n",
        "\n",
        "def convert_base_into_list(number, base, width=10):\n",
        "    result = []  # init list\n",
        "\n",
        "    for i in range(width):\n",
        "        result.append([number % base])\n",
        "        number = number // base\n",
        "    result = result[::-1]\n",
        "    return result\n",
        "\n",
        "\n",
        "def prime_to_index(primeSize, primes, number):\n",
        "    for index in range(primeSize):\n",
        "        if number == primes[index]:\n",
        "            return index\n",
        "    return -1\n",
        "\n",
        "def write_log(s ,filename='1016_Hybird_log.txt'):\n",
        "  with open(filename, 'a', encoding='utf-8') as file:\n",
        "    file.write(s)"
      ],
      "metadata": {
        "id": "DxVObRdp_GSP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaEH2nRv1EY2",
        "outputId": "7b901d84-c84f-4140-85ea-e87c3774471e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---loading data---\n",
            "---loading data done.---\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 數據轉換函數\n",
        "def convert_base_into_list(number, base, width=10):\n",
        "    result = []\n",
        "    for i in range(width):\n",
        "        result.append(number % base)\n",
        "        number = number // base\n",
        "    return result[::-1]  # 返回扁平的列表\n",
        "\n",
        "print(\"---loading data---\")\n",
        "# 加載數據\n",
        "trainData = pd.read_csv('/content/Drive/MyDrive/實驗/goldbach/csv/traindata_min_size_1000.csv')\n",
        "trainDataNumbers = trainData['Number'].values\n",
        "trainDataLabel = trainData['Factors'].values\n",
        "print(\"---loading data done.---\")\n",
        "\n",
        "# 打亂訓練數據\n",
        "shuffleIndices = np.random.permutation(len(trainDataNumbers))\n",
        "shuffledNumbers = trainDataNumbers[shuffleIndices]\n",
        "shuffledLabel = trainDataLabel[shuffleIndices]\n",
        "\n",
        "# 準備特徵\n",
        "mergedTrainNumber = []\n",
        "for num in shuffledNumbers:\n",
        "    feature = convert_base_into_list(num, 2) + convert_base_into_list(num, 3) + \\\n",
        "              convert_base_into_list(num, 5) + convert_base_into_list(num, 7)\n",
        "    mergedTrainNumber.append(feature)\n",
        "\n",
        "mergedArray = np.array(mergedTrainNumber)\n",
        "mergedLabel = np.array(shuffledLabel)\n",
        "\n",
        "# 分割數據\n",
        "X_train, X_val, y_train, y_val = train_test_split(mergedArray, mergedLabel, test_size=0.2, random_state=42)\n",
        "\n",
        "# 創建 PyTorch 數據集和數據加載器\n",
        "class GoldbachDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = torch.FloatTensor(features)\n",
        "        self.labels = torch.FloatTensor(labels).view(-1, 1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "train_dataset = GoldbachDataset(X_train, y_train)\n",
        "val_dataset = GoldbachDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=128)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 定義模型\n",
        "#input_size=40\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(MLP, self).__init__()\n",
        "    self.mlp = nn.Sequential(\n",
        "        nn.Linear(input_size, hidden_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(200, hidden_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(200, hidden_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(200, hidden_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(200, 1)\n",
        "    )\n",
        "\n",
        "  def forward (self, x):\n",
        "    return self.mlp(x)\n",
        "\n",
        "\n",
        "class LN(nn.Module):\n",
        "  def __init__(self, input_size):\n",
        "    super(LN, self).__init__()\n",
        "    self.denseG1 = nn.Linear(input_size, 120) #8:2\n",
        "    self.denseG2 = nn.Linear(input_size, 80)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    group1 = x\n",
        "    group2 = F.relu(x)\n",
        "    group2 = torch.log(group2+1)\n",
        "\n",
        "    group1 = F.relu(self.denseG1(group1))\n",
        "    group2 = self.denseG2(group2)\n",
        "    group2 = torch.exp(group2)\n",
        "\n",
        "    merged = torch.cat([group1, group2], dim=-1)\n",
        "    return merged\n",
        "\n",
        "\n",
        "class HybridModel(nn.Module):\n",
        "  def __init__(self,input_size, hidden_size):\n",
        "    super(HybridModel, self).__init__()\n",
        "    self.Mmlp = MLP(input_size, hidden_size)\n",
        "    self.Mln = LN(input_size)\n",
        "    #self.model_weight = nn.Linear(input_size, 2)#輸出兩個模型的比例\n",
        "    self.register_buffer('model_weight', torch.tensor([0.6, 0.4]))  # MLP:0.6, LN:0.4\n",
        "\n",
        "  def forward(self, x):\n",
        "    mlp_output = self.Mmlp(x)\n",
        "    ln_output  = self.Mln(x)\n",
        "    # 動態生成兩模型的權重 -> 靜態\n",
        "    # model_weight = torch.softmax(self.model_weight(x), dim=1)\n",
        "\n",
        "    # 以6:4的方式讀取mlp跟ln模型的權重\n",
        "    combined_output = self.model_weight[0] * mlp_output + self.model_weight[1] * ln_output.mean(dim=-1, keepdim=True)\n",
        "    #combined_output = model_weight[:, 0].unsqueeze(1) * mlp_output + model_weight[:, 1].unsqueeze(1) * ln_output.mean(dim=-1, keepdim=True)\n",
        "\n",
        "\n",
        "    return combined_output\n",
        "\n",
        "# 檢查是否有可用的GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"--- Using device: {device} ---\")\n",
        "\n",
        "# 創建模型實例\n",
        "input_size = X_train.shape[1]\n",
        "hiddne_size = 200 #neroal\n",
        "print(f\"Input size: {input_size}\")\n",
        "model = HybridModel(input_size, hiddne_size).to(device)\n",
        "nn.init.constant_(model.model_weight , 0.5)\n",
        "\n",
        "# 定義損失函數和優化器\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_1ajk8HOF9E",
        "outputId": "6d6bc89b-22fb-409b-bdac-83106b9d755c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Using device: cuda:0 ---\n",
            "Input size: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練模型\n",
        "print(\"---starting training---\")\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_features, batch_labels in train_loader:\n",
        "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_features)\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # 驗證\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_features, batch_labels in val_loader:\n",
        "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "            outputs = model(batch_features)\n",
        "            val_loss += criterion(outputs, batch_labels).item()\n",
        "    write_log(f\"========== \\n Epoch [{epoch+1}/{num_epochs}], Train Loss: {total_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f} \\n ========== \\n\")\n",
        "    # print(\"==========\")\n",
        "    # print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {total_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")\n",
        "    # print(\"==========\")\n",
        "\n",
        "print(\"--------------------------------------------------------\")\n",
        "\n",
        "# 保存模型\n",
        "torch.save(model.state_dict(), 'goldbach_model_0725.pth')\n",
        "print(\"model saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYFUuRH1OIAZ",
        "outputId": "c88e450f-d32e-499e-9fa4-dac07d9b4975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---starting training---\n",
            "--------------------------------------------------------\n",
            "model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training"
      ],
      "metadata": {
        "id": "ylbXzmBJmQRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lI_u090kmqfv",
        "outputId": "01f81933-bd68-43ac-f5b4-5c6db777793b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (800, 40)\n",
            "Shape of y_train: (800,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# predict"
      ],
      "metadata": {
        "id": "Kf9iJZEn-cZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/Drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nbn4CLgI-I-",
        "outputId": "5f31c5c5-1a4f-4280-ae22-0f4cfb086078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/Drive; to attempt to forcibly remount, call drive.mount(\"/content/Drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loadding prime table\n",
        "primeTable = pd.read_csv(\"/content/Drive/MyDrive/實驗/goldbach/csv/prime_table_5000000.csv\")\n",
        "primeTableNumber = primeTable[\"primes\"].values\n",
        "print (\"---loading primes table---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c8mDF4dJ9YC",
        "outputId": "d3c4a4d6-2a72-4e0f-8b38-196267383b2b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---loading primes table---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## load data\n",
        "#predict\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# load torch model\n",
        "model = HybridModel(input_size,hiddne_size)\n",
        "model.load_state_dict(torch.load('/content/Drive/MyDrive/實驗/model_save/HybirdModel_1023_6v4.pth'))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "# load test_set and prime data\n",
        "testDataPath = '/content/Drive/MyDrive/實驗/goldbach/csv/test_set_G4_5M.csv'\n",
        "testData = pd.read_csv(testDataPath)\n",
        "testDataNumbers = testData['Number'].values\n",
        "testDataLabel = testData['Factors'].values\n",
        "testDataGroundTruth = testData['Partition'].values\n",
        "\n",
        "print(\"---loading test data done.---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHHJ3UKUI4Kd",
        "outputId": "7117d645-4ef8-44a9-cb3d-f3174d4d4deb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---loading test data done.---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-234fa19fd9ce>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('/content/Drive/MyDrive/實驗/model_save/HybirdModel_1023_6v4.pth'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle training data\n",
        "shuffleIndices = np.random.permutation(len(testDataNumbers))\n",
        "shuffledNumbers = testDataNumbers[shuffleIndices]\n",
        "shuffledLabel = testDataLabel[shuffleIndices]"
      ],
      "metadata": {
        "id": "DdLMugz5KeQJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate 25 prime table\n",
        "primeTable25 = primeTableNumber[:25]\n",
        "print (primeTable25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P016SagF3Ley",
        "outputId": "167037a6-406f-4f0e-95a9-26b26867444c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2  3  5  7 11 13 17 19 23 29 31 37 41 43 47 53 59 61 67 71 73 79 83 89\n",
            " 97]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## one number\n",
        "torch version"
      ],
      "metadata": {
        "id": "lyKZ7bnBrHuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 評估模型\n",
        "model.eval()\n",
        "total_loss = 0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_features, batch_labels in val_loader:\n",
        "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "        outputs = model(batch_features)\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "average_loss = total_loss / len(val_loader)\n",
        "\n",
        "print(f\"Loss: {average_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRjgKnpLrXAk",
        "outputId": "a21a6f03-99aa-4042-a862-c648e7e71202"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 155945960.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "# 準備數據\n",
        "test_data = []  # 這裡放你想要預測的數字\n",
        "new_features = []\n",
        "for num in shuffledNumbers:\n",
        "    feature = convert_base_into_list(num, 2) + convert_base_into_list(num, 3) + \\\n",
        "              convert_base_into_list(num, 5) + convert_base_into_list(num, 7)\n",
        "    new_features.append(feature)\n",
        "\n",
        "\n",
        "\n",
        "new_features = torch.FloatTensor(new_features).to(device)\n",
        "\n",
        "# 進行預測\n",
        "with torch.no_grad():\n",
        "    predictions = model(new_features)\n",
        "\n",
        "# # 輸出結果\n",
        "\n",
        "result = predictions.cpu().numpy()[:,0]\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "oqEKGcPy6MWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "925e1e4e-cc46-4f94-ca64-0f493359c3ab"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.9482116  0.72832745 1.6123277  0.6966759  1.4261906  0.7117688\n",
            " 1.9212632  0.7736532  0.7013575  1.4450363  0.6988166  1.705915\n",
            " 1.432617   0.9373112  0.7126024  0.8671815  0.71188796 1.4058646\n",
            " 0.7381256  0.9570596  1.4041355  0.642774   0.65550727 0.7113078\n",
            " 0.9407033  1.9085459  0.71116936 0.716448   0.7113451  1.6556264\n",
            " 0.69951475 1.4671983  1.4488307  1.423585   1.437078   1.0365312\n",
            " 0.7119828  0.7100744  1.6813571  0.68357164 1.4050374  0.736928\n",
            " 0.94595337 0.7104683  1.4512129  1.4344677  0.71884346 0.7134578\n",
            " 0.7115309  1.4241629 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roundPredictions = [int(i) for i in predictions]"
      ],
      "metadata": {
        "id": "03RniE6zvfHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (len(testDataLabel))\n",
        "print (len(roundPredictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbuGvXIwwQNq",
        "outputId": "79411b8a-0fee-4a16-cfde-e9c31b7502a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# G4 normolize"
      ],
      "metadata": {
        "id": "7uD9CphSig0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G4_normolize = []\n",
        "G4 = testData['G4'].values\n",
        "for i in range(50):\n",
        "  G4_normolize.append(result[i]*G4[i])\n",
        "\n",
        "print (G4_normolize)"
      ],
      "metadata": {
        "id": "EL1SkGuAwQGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e72e2c03-2449-40e3-f197-f0e848139d60"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[49151.79670407263, 16790.971628298597, 43085.65688981386, 16605.933461880508, 37434.510147354515, 16478.759890363614, 50468.13904539849, 19305.85426948937, 18641.799463401137, 38133.10853369731, 18141.916952552718, 44298.448475393816, 37784.31538772856, 23875.533316420897, 17340.14104431132, 20344.67407933388, 16813.24863053085, 35696.107208887144, 19753.96079087368, 24285.846612558056, 33822.38140058022, 15922.481987139889, 15291.147763809364, 17178.21675673728, 22524.968951285744, 46533.874819190874, 17688.596938847542, 18902.424243603717, 18400.74803267745, 42093.237478167684, 18306.412688714256, 37617.67568817913, 36874.88065469374, 36847.42427497466, 36825.53704532495, 27315.97366481348, 17483.104766400524, 16890.533503360548, 40050.92315317608, 17797.08929623633, 33878.21607353953, 17686.764996551516, 21930.276670830386, 16974.766373623846, 34014.86451054372, 38273.61137285582, 18279.468736241455, 16505.41070785683, 16810.248219033296, 34422.63740293013]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(50):\n",
        "  print (f\"number : {testDataNumbers[i]} | Partitions : {testDataGroundTruth[i]} , prediction : {round(G4_normolize[i])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gytrLCXllIUK",
        "outputId": "fd7346ac-0ec2-4b67-bcfd-3664d119bc3b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number : 5553744 | Partitions : 41873 , prediction : 49152\n",
            "number : 5003876 | Partitions : 15970 , prediction : 16791\n",
            "number : 5935308 | Partitions : 36998 , prediction : 43086\n",
            "number : 5200696 | Partitions : 16630 , prediction : 16606\n",
            "number : 5813676 | Partitions : 41419 , prediction : 37435\n",
            "number : 5028418 | Partitions : 16170 , prediction : 16479\n",
            "number : 5818872 | Partitions : 36489 , prediction : 50468\n",
            "number : 5483820 | Partitions : 46016 , prediction : 19306\n",
            "number : 5898626 | Partitions : 21873 , prediction : 18642\n",
            "number : 5849802 | Partitions : 46833 , prediction : 38133\n",
            "number : 5740300 | Partitions : 24297 , prediction : 18142\n",
            "number : 5741998 | Partitions : 18243 , prediction : 44298\n",
            "number : 5846038 | Partitions : 20365 , prediction : 37784\n",
            "number : 5615658 | Partitions : 35177 , prediction : 23876\n",
            "number : 5326454 | Partitions : 20254 , prediction : 17340\n",
            "number : 5106104 | Partitions : 16261 , prediction : 20345\n",
            "number : 5145688 | Partitions : 16516 , prediction : 16813\n",
            "number : 5594896 | Partitions : 17868 , prediction : 35696\n",
            "number : 5945490 | Partitions : 51232 , prediction : 19754\n",
            "number : 5590980 | Partitions : 47532 , prediction : 24286\n",
            "number : 5264272 | Partitions : 18281 , prediction : 33822\n",
            "number : 5437450 | Partitions : 24484 , prediction : 15922\n",
            "number : 5072508 | Partitions : 38850 , prediction : 15291\n",
            "number : 5280070 | Partitions : 22417 , prediction : 17178\n",
            "number : 5228178 | Partitions : 34193 , prediction : 22525\n",
            "number : 5338682 | Partitions : 16924 , prediction : 46534\n",
            "number : 5463098 | Partitions : 18225 , prediction : 17689\n",
            "number : 5848392 | Partitions : 40536 , prediction : 18902\n",
            "number : 5716452 | Partitions : 43083 , prediction : 18401\n",
            "number : 5603428 | Partitions : 18047 , prediction : 42093\n",
            "number : 5793788 | Partitions : 26526 , prediction : 18306\n",
            "number : 5658164 | Partitions : 18284 , prediction : 37618\n",
            "number : 5610336 | Partitions : 35358 , prediction : 36875\n",
            "number : 5720538 | Partitions : 36243 , prediction : 36847\n",
            "number : 5654636 | Partitions : 19891 , prediction : 36826\n",
            "number : 5840642 | Partitions : 18273 , prediction : 27316\n",
            "number : 5382674 | Partitions : 18872 , prediction : 17483\n",
            "number : 5188342 | Partitions : 16884 , prediction : 16891\n",
            "number : 5196820 | Partitions : 21970 , prediction : 40051\n",
            "number : 5759344 | Partitions : 18317 , prediction : 17797\n",
            "number : 5270408 | Partitions : 21718 , prediction : 33878\n",
            "number : 5242284 | Partitions : 33465 , prediction : 17687\n",
            "number : 5036312 | Partitions : 16123 , prediction : 21930\n",
            "number : 5214934 | Partitions : 16532 , prediction : 16975\n",
            "number : 5100624 | Partitions : 32749 , prediction : 34015\n",
            "number : 5924730 | Partitions : 59999 , prediction : 38274\n",
            "number : 5604610 | Partitions : 25988 , prediction : 18279\n",
            "number : 5024032 | Partitions : 17537 , prediction : 16505\n",
            "number : 5147612 | Partitions : 17005 , prediction : 16810\n",
            "number : 5285190 | Partitions : 46055 , prediction : 34423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## normolize with partition"
      ],
      "metadata": {
        "id": "VsRkjQ2Cjojf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mse(predictions, targets):\n",
        "    \"\"\"\n",
        "    計算均方誤差 (MSE)\n",
        "\n",
        "    參數:\n",
        "    predictions: 預測值的列表或陣列\n",
        "    targets: 實際值的列表或陣列，與預測值對應\n",
        "\n",
        "    返回值:\n",
        "    mse: 均方誤差\n",
        "    \"\"\"\n",
        "    # 確保預測值和實際值的長度相等\n",
        "    if len(predictions) != len(targets):\n",
        "        raise ValueError(\"預測值和實際值的長度不一致\")\n",
        "\n",
        "    # 計算平方誤差\n",
        "    squared_errors = [(p - t) ** 2 for p, t in zip(predictions, targets)]\n",
        "\n",
        "    # 計算均方誤差\n",
        "    mse = sum(squared_errors) / len(predictions)\n",
        "\n",
        "    return mse\n",
        "\n",
        "# 使用 LN\n",
        "\n",
        "\n",
        "# 使用 MLP(old)\n",
        "#mse_result = calculate_mse(predictions, testDataPartition)\n",
        "\n",
        "\n",
        "import math\n",
        "mean = testData['Partition'].mean()\n",
        "MSE = calculate_mse(G4_normolize, testDataGroundTruth)\n",
        "\n",
        "RMSE= math.sqrt(MSE)\n",
        "errorRate = RMSE/mean\n",
        "\n",
        "print (f\"MSE : {MSE} / ({MSE/1000000})\\nRMSE : {RMSE}\\nError Rate : {errorRate}  ->  {round(errorRate,7)*100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4R1ElRzhZ43",
        "outputId": "4b70e33a-a1d2-451c-d269-0a1183939708"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE : 198634497.85231605 / (198.63449785231606)\n",
            "RMSE : 14093.775145514279\n",
            "Error Rate : 0.5103315413936494  ->  51.033150000000006%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QPfacTQykHBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## normolize with G4"
      ],
      "metadata": {
        "id": "qm2EW949lxH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mse(predictions, targets):\n",
        "    \"\"\"\n",
        "    計算均方誤差 (MSE)\n",
        "\n",
        "    參數:\n",
        "    predictions: 預測值的列表或陣列\n",
        "    targets: 實際值的列表或陣列，與預測值對應\n",
        "\n",
        "    返回值:\n",
        "    mse: 均方誤差\n",
        "    \"\"\"\n",
        "    # 確保預測值和實際值的長度相等\n",
        "    if len(predictions) != len(targets):\n",
        "        raise ValueError(\"預測值和實際值的長度不一致\")\n",
        "\n",
        "    # 計算平方誤差\n",
        "    squared_errors = [(p - t) ** 2 for p, t in zip(predictions, targets)]\n",
        "\n",
        "    # 計算均方誤差\n",
        "    mse = sum(squared_errors) / len(predictions)\n",
        "\n",
        "    return mse\n",
        "\n",
        "# 使用 LN\n",
        "\n",
        "\n",
        "\n",
        "import math\n",
        "mean = testData['Factors'].mean()\n",
        "MSE = calculate_mse(result, testDataLabel)\n",
        "\n",
        "RMSE= math.sqrt(MSE)\n",
        "errorRate = RMSE/mean\n",
        "\n",
        "print (f\"MSE : {MSE}\\nRMSE : {RMSE}\\nError Rate : {errorRate}  ->  {round(errorRate,7)*100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Vpo6awVl0Xq",
        "outputId": "b51539e9-7a02-4b61-bbf0-3961e39e4d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE : 0.40544219032581863\n",
            "RMSE : 0.6367434258206508\n",
            "Error Rate : 0.5790622225267348  ->  57.90622%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QOs-KaQKmHMR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}