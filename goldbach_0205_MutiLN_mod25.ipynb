{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTJzijKyILOuewT5vT+gTb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bread806/goldbach_backup_from_colab/blob/main/goldbach_0205_MutiLN_mod25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# mod 25 實驗結果測試\n",
        "<a href=\"https://drive.google.com/file/d/1RzHAFqRE0sV5uXkwbzjXXo0uOHL8SFRo/view?usp=sharing\">請見paper</a><br>\n",
        "要對 G4 做正規化"
      ],
      "metadata": {
        "id": "O-1Ma6ex2-KZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/Drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNYcmX52zpq7",
        "outputId": "c034c1e8-d3cb-4bcd-b398-a5c0091dff8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.keras.layers import Embedding, Dense, Flatten, LayerNormalization, Input,Activation, concatenate, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from random import choice, sample\n",
        "import math\n",
        "\n",
        "\n",
        "def is_prime(num):\n",
        "    \"\"\"檢查一個數字是否為質數\"\"\"\n",
        "    if num <= 1:\n",
        "        return False\n",
        "    sqr_num = int(num ** 0.5)\n",
        "    # for i in range(2, sqr_num+ 1):\n",
        "    for i in range(2, sqr_num+ 1):\n",
        "        if num % i == 0:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def prime_table(x):\n",
        "    \"\"\"建立小於x的質數表\"\"\"\n",
        "    primes = [num for num in range(2, x) if is_prime(num)]\n",
        "    return primes\n",
        "\n",
        "\n",
        "def convert_base_into_list(number, base, width=10):\n",
        "    result = []  # init list\n",
        "\n",
        "    for i in range(width):\n",
        "        result.append(number % base)\n",
        "        number = number // base\n",
        "    result = result[::-1]\n",
        "    return result\n",
        "\n",
        "\n",
        "def prime_to_index(primeSize, primes, number):\n",
        "    for index in range(primeSize):\n",
        "        if number == primes[index]:\n",
        "            return index\n",
        "    return -1\n",
        "\n",
        "def add_prime(primeTable, limit, addSize=5):\n",
        "    halfList = [num for num in primeTable if num <= int(limit//2)]\n",
        "    if len(halfList) < 5:\n",
        "      halfList += [0] * (5 - len(halfList))\n",
        "    return sample(halfList, addSize)\n",
        "\n",
        "def add_mod(primeTable25, num):\n",
        "  return [num%index for index in primeTable25]\n",
        "\n",
        "def gcd(a, b):\n",
        "    while b != 0:\n",
        "        a, b = b, a % b\n",
        "    return a\n",
        "\n",
        "\n",
        "def compute_coprimes(n): ## 獲得質因數 zero padding 到40\n",
        "    coprimes = []\n",
        "    lenth = 50\n",
        "    for num in range(1,n):\n",
        "        if gcd(num , n) == 1:\n",
        "            coprimes.append(num)\n",
        "        if len(coprimes) >= lenth:\n",
        "            return coprimes\n",
        "    coprimes = coprimes + [0] * (lenth - len(coprimes))\n",
        "    return coprimes\n"
      ],
      "metadata": {
        "id": "Veno4zyPzi57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdPvfso6zdJ2",
        "outputId": "4daf38f4-e4e8-488a-8820-c4926b9d6ee6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---loading data---\n",
            "---loading data done.---\n"
          ]
        }
      ],
      "source": [
        "# shuffle\n",
        "\n",
        "print(\"---loading data---\")\n",
        "# load data\n",
        "trainData = pd.read_csv('/content/Drive/MyDrive/實驗/goldbach/csv/traindata_DividebyG4.csv')\n",
        "trainDataNumbers = trainData['Number'].values\n",
        "trainDataLabel = trainData['Factors'].values\n",
        "print(\"---loading data done.---\")\n",
        "\n",
        "# shuffle training data\n",
        "shuffleIndices = np.random.permutation(len(trainDataNumbers))\n",
        "shuffledNumbers = trainDataNumbers[shuffleIndices]\n",
        "shuffledLabel = trainDataLabel[shuffleIndices]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (len(trainDataNumbers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0VWLQPK6F7a",
        "outputId": "09a49d15-eee7-4ca7-861d-14f6386f65ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1048575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loadding prime table\n",
        "primeTable = pd.read_csv(\"/content/Drive/MyDrive/實驗/goldbach/csv/prime_table_5000000.csv\")\n",
        "primeTableNumber = primeTable[\"primes\"].values\n",
        "print (\"---loading primes table---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5qpkhdJ0ZlU",
        "outputId": "8066a70c-ac1e-4dde-9964-2d000f6076b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---loading primes table---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XjDFb9Z-GlrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate 25 prime table\n",
        "primeTable25 = primeTableNumber[:25]\n",
        "print (primeTable25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkqY4sWrMaNh",
        "outputId": "98b9dbcf-ae76-45cc-c7bb-fecb7a6277cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2  3  5  7 11 13 17 19 23 29 31 37 41 43 47 53 59 61 67 71 73 79 83 89\n",
            " 97]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# collect data\n",
        "# prepare training set\n",
        "mergedTrainNumber = []\n",
        "mergedTrainLabel = []\n",
        "\n",
        "for num in shuffledNumbers:\n",
        "\n",
        "    #add 25 prefix prime\n",
        "    feature = []\n",
        "    feature = add_mod(primeTable25, num)\n",
        "    mergedTrainNumber.append(feature)\n",
        "\n",
        "for num in shuffledLabel:\n",
        "    mergedTrainLabel.append(num)\n",
        "\n",
        "    print(\"merge number \", num, \" done.\")\n",
        "\n",
        "#print (mergedTrainNumber)"
      ],
      "metadata": {
        "id": "3MZY96_M0KIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mergedArray = np.array(mergedTrainNumber)\n",
        "mergedLabel = np.array(mergedTrainLabel)"
      ],
      "metadata": {
        "id": "R4v5443kK8Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(mergedArray, mergedLabel, test_size=0.2, random_state=42)\n",
        "print (\"X Train [0] value : \\n\",X_train[0])\n",
        "print (\"X Train [0] label : \",y_train[0])\n",
        "print (\"=======\")\n",
        "print (\"X shpae : \" , X_train[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyTwBG1jzoK8",
        "outputId": "657fd414-d3a3-4098-9a82-2eaa2e641ac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train [0] value : \n",
            " [ 0  2  2  0  2  3 16 16  6  0  7  0 29 33 38 43 19 38 56  0 32 62 12 75\n",
            " 47]\n",
            "X Train [0] label :  0.90454345\n",
            "=======\n",
            "X shpae :  (25,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TtSW_xrT7LAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start training\n",
        "# 清空所有\n",
        "K.clear_session()\n",
        "\n",
        "################################################################\n",
        "\n",
        "def LN_Layer(x):\n",
        "  # two group\n",
        "  group1 = x\n",
        "  group2 = Activation('relu')(x)\n",
        "  group2 = Lambda(lambda x: K.log(x + 1))(group2)  # 使用 natural logarithm\n",
        "\n",
        "  # G1 -> next\n",
        "  group1 = Dense(units=120, activation='relu')(group1)\n",
        "\n",
        "  # G2 -> exp -> next\n",
        "  group2 = Dense(units=80, activation='linear')(group2)\n",
        "  group2 = Activation('exponential')(group2)\n",
        "\n",
        "  # concate\n",
        "  merged = concatenate([group1, group2], axis=-1)\n",
        "\n",
        "  return merged\n",
        "\n",
        "\n",
        "# require gpu\n",
        "device = \"/device:GPU:0\"\n",
        "with tf.device(device):\n",
        "    print(f\"--- gpu {device} is loaded. ---\")\n",
        "    inputLayer = Input(shape=X_train[0].shape)\n",
        "\n",
        "    # 先加兩層\n",
        "    x = Dense(units=25, activation='relu')(inputLayer)\n",
        "    x = Dense(units=200, activation='relu')(x)\n",
        "\n",
        "    #LN\n",
        "    LNOut = LN_Layer(x)\n",
        "\n",
        "    # 後加兩層\n",
        "    x = Dense(units=200, activation='relu')(LNOut)\n",
        "    x = Dense(units=200, activation='relu')(x)\n",
        "\n",
        "    #Output\n",
        "    outputLayer = Dense(units=1, activation='linear')(x)\n",
        "    model = Model(inputs=inputLayer , outputs=outputLayer)\n",
        "\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    custom_adam_optimizer = Adam(learning_rate=0.001)\n",
        "    model.compile(loss='MSE', optimizer=custom_adam_optimizer,\n",
        "                  metrics=['accuracy'])    # train version 2\n",
        "\n",
        "    # train model\n",
        "    print(\"---starting training---\")\n",
        "    trainHistory = model.fit(X_train, y_train, epochs=200,batch_size=2048, validation_data=(X_val, y_val))\n",
        "    print(\"--------------------------------------------------------\")\n",
        "\n",
        "    # save model\n",
        "    #model.save('./csv/goldbach_model_1112_400w.h5')\n",
        "print(\"model saved.\")\n"
      ],
      "metadata": {
        "id": "ge8BVKMTznDr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a74a5a-69a0-4713-ef49-ebc271e67492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- gpu /device:GPU:0 is loaded. ---\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 25)]                 0         []                            \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 26)                   676       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 200)                  5400      ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 200)                  0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " lambda (Lambda)             (None, 200)                  0         ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 200)                  40200     ['lambda[0][0]']              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 200)                  40200     ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 200)                  0         ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 400)                  0         ['dense_2[0][0]',             \n",
            "                                                                     'activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 200)                  80200     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 200)                  40200     ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 1)                    201       ['dense_5[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 207077 (808.89 KB)\n",
            "Trainable params: 207077 (808.89 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "---starting training---\n",
            "Epoch 1/200\n",
            "410/410 [==============================] - 108s 225ms/step - loss: 0.6000 - accuracy: 0.0000e+00 - val_loss: 0.1720 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "410/410 [==============================] - 78s 190ms/step - loss: 0.1712 - accuracy: 0.0000e+00 - val_loss: 0.1701 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/200\n",
            "410/410 [==============================] - 93s 226ms/step - loss: 0.1698 - accuracy: 0.0000e+00 - val_loss: 0.1706 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/200\n",
            "410/410 [==============================] - 79s 192ms/step - loss: 0.1249 - accuracy: 0.0000e+00 - val_loss: 0.0387 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/200\n",
            "410/410 [==============================] - 75s 182ms/step - loss: 0.0247 - accuracy: 0.0000e+00 - val_loss: 0.0203 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/200\n",
            "410/410 [==============================] - 75s 184ms/step - loss: 0.0189 - accuracy: 0.0000e+00 - val_loss: 0.0183 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/200\n",
            "410/410 [==============================] - 86s 210ms/step - loss: 0.0181 - accuracy: 0.0000e+00 - val_loss: 0.0167 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/200\n",
            "410/410 [==============================] - 68s 166ms/step - loss: 0.0171 - accuracy: 0.0000e+00 - val_loss: 0.0156 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/200\n",
            "410/410 [==============================] - 34s 83ms/step - loss: 0.0157 - accuracy: 0.0000e+00 - val_loss: 0.0129 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/200\n",
            "410/410 [==============================] - 30s 72ms/step - loss: 0.0163 - accuracy: 0.0000e+00 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/200\n",
            "410/410 [==============================] - 34s 83ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0087 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0097 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/200\n",
            "410/410 [==============================] - 30s 72ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/200\n",
            "410/410 [==============================] - 29s 72ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/200\n",
            "410/410 [==============================] - 33s 80ms/step - loss: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/200\n",
            "410/410 [==============================] - 29s 72ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/200\n",
            "410/410 [==============================] - 30s 72ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/200\n",
            "410/410 [==============================] - 36s 88ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0032 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/200\n",
            "410/410 [==============================] - 33s 80ms/step - loss: 0.0033 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0035 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0030 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0028 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/200\n",
            "410/410 [==============================] - 33s 80ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0025 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/200\n",
            "410/410 [==============================] - 30s 72ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/200\n",
            "410/410 [==============================] - 33s 80ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0018 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0018 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/200\n",
            "410/410 [==============================] - 34s 83ms/step - loss: 0.0017 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0018 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/200\n",
            "410/410 [==============================] - 31s 75ms/step - loss: 0.0017 - accuracy: 0.0000e+00 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0021 - accuracy: 0.0000e+00 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0017 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0017 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0017 - accuracy: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0016 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/200\n",
            "410/410 [==============================] - 33s 81ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0021 - accuracy: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0017 - accuracy: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/200\n",
            "410/410 [==============================] - 31s 74ms/step - loss: 0.0012 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0016 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/200\n",
            "410/410 [==============================] - 32s 79ms/step - loss: 0.0010 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0010 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0015 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0012 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/200\n",
            "410/410 [==============================] - 33s 80ms/step - loss: 0.0011 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/200\n",
            "410/410 [==============================] - 35s 86ms/step - loss: 0.0011 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0011 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0013 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/200\n",
            "410/410 [==============================] - 33s 80ms/step - loss: 0.0011 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0011 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0011 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/200\n",
            "410/410 [==============================] - 31s 75ms/step - loss: 0.0022 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/200\n",
            "410/410 [==============================] - 31s 75ms/step - loss: 0.0010 - accuracy: 0.0000e+00 - val_loss: 9.9990e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/200\n",
            "410/410 [==============================] - 31s 75ms/step - loss: 9.9682e-04 - accuracy: 0.0000e+00 - val_loss: 9.6147e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/200\n",
            "410/410 [==============================] - 31s 76ms/step - loss: 0.0010 - accuracy: 0.0000e+00 - val_loss: 9.6461e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0026 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0011 - accuracy: 0.0000e+00 - val_loss: 9.7750e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/200\n",
            "410/410 [==============================] - 31s 74ms/step - loss: 9.8931e-04 - accuracy: 0.0000e+00 - val_loss: 9.3594e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/200\n",
            "410/410 [==============================] - 31s 75ms/step - loss: 9.9822e-04 - accuracy: 0.0000e+00 - val_loss: 9.3676e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 9.6911e-04 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/200\n",
            "410/410 [==============================] - 33s 80ms/step - loss: 9.7371e-04 - accuracy: 0.0000e+00 - val_loss: 9.7074e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/200\n",
            "410/410 [==============================] - 31s 75ms/step - loss: 0.0027 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0013 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/200\n",
            "410/410 [==============================] - 31s 75ms/step - loss: 0.0010 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/200\n",
            "410/410 [==============================] - 31s 75ms/step - loss: 9.7345e-04 - accuracy: 0.0000e+00 - val_loss: 9.3615e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/200\n",
            "410/410 [==============================] - 36s 87ms/step - loss: 9.5495e-04 - accuracy: 0.0000e+00 - val_loss: 9.4399e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/200\n",
            "410/410 [==============================] - 31s 75ms/step - loss: 9.4493e-04 - accuracy: 0.0000e+00 - val_loss: 9.5504e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/200\n",
            "410/410 [==============================] - 31s 74ms/step - loss: 0.0226 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/200\n",
            "410/410 [==============================] - 31s 75ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/200\n",
            "410/410 [==============================] - 31s 75ms/step - loss: 0.0036 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/200\n",
            "410/410 [==============================] - 33s 82ms/step - loss: 0.0027 - accuracy: 0.0000e+00 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/200\n",
            "410/410 [==============================] - 31s 75ms/step - loss: 0.0022 - accuracy: 0.0000e+00 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/200\n",
            "410/410 [==============================] - 31s 75ms/step - loss: 0.0018 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/200\n",
            "410/410 [==============================] - 31s 75ms/step - loss: 0.0016 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0016 - accuracy: 0.0000e+00 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/200\n",
            "410/410 [==============================] - 31s 76ms/step - loss: 0.0015 - accuracy: 0.0000e+00 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0014 - accuracy: 0.0000e+00 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/200\n",
            "410/410 [==============================] - 31s 75ms/step - loss: 0.0014 - accuracy: 0.0000e+00 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0013 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/200\n",
            "410/410 [==============================] - 31s 75ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/200\n",
            "410/410 [==============================] - 31s 75ms/step - loss: 0.0030 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/200\n",
            "410/410 [==============================] - 33s 81ms/step - loss: 0.0015 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/200\n",
            "410/410 [==============================] - 31s 75ms/step - loss: 0.0011 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/200\n",
            "410/410 [==============================] - 31s 75ms/step - loss: 0.0010 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0010 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0010 - accuracy: 0.0000e+00 - val_loss: 9.7820e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/200\n",
            "410/410 [==============================] - 33s 80ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/200\n",
            "410/410 [==============================] - 29s 71ms/step - loss: 0.0011 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/200\n",
            "410/410 [==============================] - 35s 85ms/step - loss: 0.0010 - accuracy: 0.0000e+00 - val_loss: 9.7651e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/200\n",
            "410/410 [==============================] - 30s 72ms/step - loss: 9.8403e-04 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/200\n",
            "410/410 [==============================] - 30s 72ms/step - loss: 9.8342e-04 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 9.8536e-04 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/200\n",
            "410/410 [==============================] - 29s 72ms/step - loss: 9.8883e-04 - accuracy: 0.0000e+00 - val_loss: 9.5572e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/200\n",
            "410/410 [==============================] - 29s 72ms/step - loss: 9.8797e-04 - accuracy: 0.0000e+00 - val_loss: 9.6878e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/200\n",
            "410/410 [==============================] - 29s 71ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/200\n",
            "410/410 [==============================] - 29s 71ms/step - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/200\n",
            "410/410 [==============================] - 30s 72ms/step - loss: 0.0021 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/200\n",
            "410/410 [==============================] - 30s 72ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/200\n",
            "410/410 [==============================] - 32s 77ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/200\n",
            "410/410 [==============================] - 29s 71ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/200\n",
            "410/410 [==============================] - 29s 71ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/200\n",
            "410/410 [==============================] - 29s 71ms/step - loss: 0.0018 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/200\n",
            "410/410 [==============================] - 30s 72ms/step - loss: 0.0018 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/200\n",
            "410/410 [==============================] - 32s 78ms/step - loss: 0.0017 - accuracy: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/200\n",
            "410/410 [==============================] - 29s 71ms/step - loss: 0.0017 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0015 - accuracy: 0.0000e+00 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 131/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0014 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0012 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/200\n",
            "410/410 [==============================] - 32s 79ms/step - loss: 0.0012 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 134/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0012 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 135/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0011 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/200\n",
            "410/410 [==============================] - 37s 89ms/step - loss: 0.0021 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 137/200\n",
            "410/410 [==============================] - 30s 72ms/step - loss: 0.0015 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 138/200\n",
            "410/410 [==============================] - 29s 71ms/step - loss: 0.0011 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/200\n",
            "410/410 [==============================] - 29s 71ms/step - loss: 0.0011 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/200\n",
            "410/410 [==============================] - 29s 71ms/step - loss: 0.0011 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 141/200\n",
            "410/410 [==============================] - 29s 71ms/step - loss: 0.0011 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 142/200\n",
            "410/410 [==============================] - 29s 71ms/step - loss: 0.0010 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 143/200\n",
            "410/410 [==============================] - 32s 79ms/step - loss: 0.0010 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/200\n",
            "410/410 [==============================] - 29s 71ms/step - loss: 0.0010 - accuracy: 0.0000e+00 - val_loss: 9.8835e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 145/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0010 - accuracy: 0.0000e+00 - val_loss: 9.6003e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 146/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 9.6850e-04 - accuracy: 0.0000e+00 - val_loss: 9.4228e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 147/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 9.6503e-04 - accuracy: 0.0000e+00 - val_loss: 9.2079e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 148/200\n",
            "410/410 [==============================] - 32s 79ms/step - loss: 9.4801e-04 - accuracy: 0.0000e+00 - val_loss: 9.2652e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 149/200\n",
            "410/410 [==============================] - 29s 71ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 150/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0012 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 151/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0011 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 152/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 0.0010 - accuracy: 0.0000e+00 - val_loss: 9.8327e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 153/200\n",
            "410/410 [==============================] - 33s 79ms/step - loss: 9.6518e-04 - accuracy: 0.0000e+00 - val_loss: 9.5331e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 154/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 9.6413e-04 - accuracy: 0.0000e+00 - val_loss: 9.3572e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 155/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 9.5019e-04 - accuracy: 0.0000e+00 - val_loss: 9.4103e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 156/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 9.3374e-04 - accuracy: 0.0000e+00 - val_loss: 9.2051e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 157/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 9.3353e-04 - accuracy: 0.0000e+00 - val_loss: 9.9746e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 158/200\n",
            "410/410 [==============================] - 32s 79ms/step - loss: 9.3769e-04 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 159/200\n",
            "410/410 [==============================] - 29s 71ms/step - loss: 9.4436e-04 - accuracy: 0.0000e+00 - val_loss: 9.0828e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 160/200\n",
            "410/410 [==============================] - 36s 88ms/step - loss: 9.2544e-04 - accuracy: 0.0000e+00 - val_loss: 8.9722e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 161/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 9.2245e-04 - accuracy: 0.0000e+00 - val_loss: 9.1533e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 162/200\n",
            "410/410 [==============================] - 32s 79ms/step - loss: 9.2747e-04 - accuracy: 0.0000e+00 - val_loss: 9.0144e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 163/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 9.2883e-04 - accuracy: 0.0000e+00 - val_loss: 8.9039e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 164/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 9.1350e-04 - accuracy: 0.0000e+00 - val_loss: 9.0765e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 165/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 9.0619e-04 - accuracy: 0.0000e+00 - val_loss: 8.7989e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 166/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 8.7082e-04 - accuracy: 0.0000e+00 - val_loss: 8.6912e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/200\n",
            "410/410 [==============================] - 32s 79ms/step - loss: 8.4509e-04 - accuracy: 0.0000e+00 - val_loss: 8.0104e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 8.0756e-04 - accuracy: 0.0000e+00 - val_loss: 8.1019e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 7.9436e-04 - accuracy: 0.0000e+00 - val_loss: 8.2012e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/200\n",
            "410/410 [==============================] - 29s 71ms/step - loss: 7.8189e-04 - accuracy: 0.0000e+00 - val_loss: 7.5799e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 171/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 7.4363e-04 - accuracy: 0.0000e+00 - val_loss: 7.6944e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 7.4139e-04 - accuracy: 0.0000e+00 - val_loss: 7.0769e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/200\n",
            "410/410 [==============================] - 29s 71ms/step - loss: 7.1072e-04 - accuracy: 0.0000e+00 - val_loss: 7.4430e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/200\n",
            "410/410 [==============================] - 29s 71ms/step - loss: 7.0751e-04 - accuracy: 0.0000e+00 - val_loss: 6.8138e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 6.9363e-04 - accuracy: 0.0000e+00 - val_loss: 6.7839e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 8.4993e-04 - accuracy: 0.0000e+00 - val_loss: 7.3323e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 7.0806e-04 - accuracy: 0.0000e+00 - val_loss: 6.9769e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 6.9386e-04 - accuracy: 0.0000e+00 - val_loss: 6.9550e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/200\n",
            "410/410 [==============================] - 29s 72ms/step - loss: 6.8404e-04 - accuracy: 0.0000e+00 - val_loss: 6.8749e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 6.7656e-04 - accuracy: 0.0000e+00 - val_loss: 7.0955e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 6.7389e-04 - accuracy: 0.0000e+00 - val_loss: 6.6013e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/200\n",
            "410/410 [==============================] - 33s 80ms/step - loss: 6.6356e-04 - accuracy: 0.0000e+00 - val_loss: 6.5503e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/200\n",
            "410/410 [==============================] - 36s 87ms/step - loss: 6.6158e-04 - accuracy: 0.0000e+00 - val_loss: 6.6396e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 185/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 6.5269e-04 - accuracy: 0.0000e+00 - val_loss: 6.6768e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 186/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 6.5329e-04 - accuracy: 0.0000e+00 - val_loss: 6.3702e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/200\n",
            "410/410 [==============================] - 33s 79ms/step - loss: 6.4426e-04 - accuracy: 0.0000e+00 - val_loss: 6.6217e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 188/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 6.4168e-04 - accuracy: 0.0000e+00 - val_loss: 7.1929e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 189/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 6.5524e-04 - accuracy: 0.0000e+00 - val_loss: 6.7405e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 190/200\n",
            "410/410 [==============================] - 30s 73ms/step - loss: 6.2002e-04 - accuracy: 0.0000e+00 - val_loss: 6.2982e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 191/200\n",
            "410/410 [==============================] - 30s 74ms/step - loss: 6.1394e-04 - accuracy: 0.0000e+00 - val_loss: 5.8864e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 192/200\n",
            "410/410 [==============================] - 32s 77ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
            "Epoch 193/200\n",
            "410/410 [==============================] - 31s 76ms/step - loss: 0.0012 - accuracy: 0.0000e+00 - val_loss: 7.4655e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 194/200\n",
            "410/410 [==============================] - 31s 76ms/step - loss: 7.1514e-04 - accuracy: 0.0000e+00 - val_loss: 6.8877e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 195/200\n",
            "410/410 [==============================] - 31s 77ms/step - loss: 6.8579e-04 - accuracy: 0.0000e+00 - val_loss: 7.9430e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 196/200\n",
            "410/410 [==============================] - 34s 84ms/step - loss: 6.7546e-04 - accuracy: 0.0000e+00 - val_loss: 6.7379e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 197/200\n",
            "410/410 [==============================] - 31s 77ms/step - loss: 6.7491e-04 - accuracy: 0.0000e+00 - val_loss: 6.4069e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 198/200\n",
            "410/410 [==============================] - 31s 76ms/step - loss: 6.6330e-04 - accuracy: 0.0000e+00 - val_loss: 6.4156e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 199/200\n",
            "410/410 [==============================] - 34s 83ms/step - loss: 6.4678e-04 - accuracy: 0.0000e+00 - val_loss: 7.0891e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 200/200\n",
            "410/410 [==============================] - 31s 76ms/step - loss: 6.4786e-04 - accuracy: 0.0000e+00 - val_loss: 6.0180e-04 - val_accuracy: 0.0000e+00\n",
            "--------------------------------------------------------\n",
            "model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## predict"
      ],
      "metadata": {
        "id": "hQJtQBsxISQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/Drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nbn4CLgI-I-",
        "outputId": "d5089e42-4297-4a68-9606-6f326cf0cd9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loadding prime table\n",
        "primeTable = pd.read_csv(\"/content/Drive/MyDrive/實驗/goldbach/csv/prime_table_5000000.csv\")\n",
        "primeTableNumber = primeTable[\"primes\"].values\n",
        "print (\"---loading primes table---\")\n",
        "\n",
        "# generate 25 prime table\n",
        "primeTable25 = primeTableNumber[:25]\n",
        "print (primeTable25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c8mDF4dJ9YC",
        "outputId": "0a8c775a-b7ab-4b12-e04a-1b92e5af3b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---loading primes table---\n",
            "[ 2  3  5  7 11 13 17 19 23 29 31 37 41 43 47 53 59 61 67 71 73 79 83 89\n",
            " 97]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## load data\n",
        "#predict\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 指定 HDF5 模型文件的路徑\n",
        "modelPath = '/content/Drive/MyDrive/實驗/model_save/goldbach_model_0205_400w.h5'\n",
        "\n",
        "# 使用 load_model\n",
        "model = load_model(modelPath)\n",
        "\n",
        "# load test_set and prime data\n",
        "testDataPath = '/content/Drive/MyDrive/實驗/goldbach/csv/test_set_G4_0.csv'\n",
        "testData = pd.read_csv(testDataPath)\n",
        "testDataNumbers = testData['Number'].values\n",
        "testDataLabel = testData['Factors'].values\n",
        "testDataG4 = testData['G4'].values\n",
        "testDataPartition = testData['Partition'].values\n",
        "\n",
        "print(\"---loading test data done.---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHHJ3UKUI4Kd",
        "outputId": "b283c553-5aec-434d-9dba-b00ac16d7451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---loading test data done.---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# collect data\n",
        "# prepare training set\n",
        "mergedTestNumber = []\n",
        "mergedTestLabel = []\n",
        "\n",
        "for num in testDataNumbers:\n",
        "\n",
        "    ### mod25\n",
        "    feature = []\n",
        "    feature = add_mod(primeTable25, num)\n",
        "    mergedTestNumber.append(feature)\n",
        "\n",
        "for num in testDataPartition:\n",
        "    mergedTestLabel.append(num)"
      ],
      "metadata": {
        "id": "w0gtoY8mStjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mergedArray = np.array(mergedTestNumber)\n",
        "mergedLabel = np.array(mergedTestLabel)"
      ],
      "metadata": {
        "id": "NqG32lBzKND0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (mergedTestNumber[0])\n",
        "print (mergedLabel[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7RPyTUXJDfy",
        "outputId": "8dbc6478-ebc5-4dab-ecdc-fed19cbb8ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 2, 3, 1, 5, 8, 8, 5, 7, 6, 9, 3, 27, 39, 19, 26, 51, 46, 55, 38, 21, 36, 20, 4, 65]\n",
            "8617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = model.evaluate(mergedArray, mergedLabel)\n",
        "#XNewData = testDataNumbers, testDataLabel\n",
        "print (\"Loss:\", evaluation[0])\n",
        "print (\"Accuracy:\", evaluation[1])\n",
        "print (\"##########################\")\n",
        "predictions = model.predict(mergedArray)\n",
        "\n"
      ],
      "metadata": {
        "id": "Jn3qRRzIKwVH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a705544-4cf5-4dbd-f7bc-825e9bb08656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 13ms/step - loss: 138463360.0000 - accuracy: 0.0000e+00\n",
            "Loss: 138463360.0\n",
            "Accuracy: 0.0\n",
            "##########################\n",
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (f\"測試五十筆資料\")\n",
        "roundPredictions = np.round(predictions)\n",
        "for index, number in enumerate(testDataNumbers):\n",
        "  print (f\"第{index}筆資料為數字:\\t{number}\\t|正確答案為:{testDataPartition[index]}\\t模型預估為{predictions[index]}, 四捨五入到{roundPredictions[index]}\")\n",
        "print (testDataNumbers[:5])\n",
        "print (testDataLabel[:5])\n",
        "print (predictions[:5])\n"
      ],
      "metadata": {
        "id": "aBJHTke7LvXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# +N 才要執行正規"
      ],
      "metadata": {
        "id": "HSrRRRUCxEBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print (f\"將50筆測資正規化回G4\")\n",
        "normalizedTest = []\n",
        "normalizedPred = []\n",
        "for index in range(len(testDataLabel)):\n",
        "  normalizedTest.append(testDataLabel[index]*testDataG4[index]) # normalize ground truth\n",
        "  normalizedPred.append(predictions[index]*testDataG4[index])  # normalize predition\n"
      ],
      "metadata": {
        "id": "kpj8x56en-uY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be372591-c9a4-43d5-83cd-12a534aa2706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "將50筆測資正規化回G4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (f\"將50筆測資正規化回G4\")\n",
        "for index, number in enumerate(testDataNumbers):\n",
        "  print (f\"第{index}筆資料為數字:\\t{number}\\t|正確答案 = {testDataPartition[index]}\\t模型預估 = {int(normalizedPred[index])}\")"
      ],
      "metadata": {
        "id": "oNLdiKSHmozC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4e5f8b7-d158-4648-b098-c5e344668d3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "將50筆測資正規化回G4\n",
            "第0筆資料為數字:\t2413328\t|正確答案 = 8617\t模型預估 = 8730\n",
            "第1筆資料為數字:\t2063850\t|正確答案 = 19867\t模型預估 = 20022\n",
            "第2筆資料為數字:\t2127556\t|正確答案 = 8004\t模型預估 = 7827\n",
            "第3筆資料為數字:\t2738944\t|正確答案 = 10361\t模型預估 = 10717\n",
            "第4筆資料為數字:\t3396126\t|正確答案 = 23485\t模型預估 = 23149\n",
            "第5筆資料為數字:\t3285178\t|正確答案 = 12582\t模型預估 = 12442\n",
            "第6筆資料為數字:\t1222818\t|正確答案 = 10215\t模型預估 = 9753\n",
            "第7筆資料為數字:\t2319246\t|正確答案 = 17107\t模型預估 = 16721\n",
            "第8筆資料為數字:\t2093692\t|正確答案 = 7593\t模型預估 = 7747\n",
            "第9筆資料為數字:\t2549384\t|正確答案 = 9229\t模型預估 = 9116\n",
            "第10筆資料為數字:\t1991774\t|正確答案 = 7271\t模型預估 = 7307\n",
            "第11筆資料為數字:\t2938648\t|正確答案 = 10311\t模型預估 = 10326\n",
            "第12筆資料為數字:\t1310512\t|正確答案 = 6145\t模型預估 = 6229\n",
            "第13筆資料為數字:\t975824\t|正確答案 = 4055\t模型預估 = 4063\n",
            "第14筆資料為數字:\t1899278\t|正確答案 = 7413\t模型預估 = 7433\n",
            "第15筆資料為數字:\t2829450\t|正確答案 = 28467\t模型預估 = 28692\n",
            "第16筆資料為數字:\t942238\t|正確答案 = 4255\t模型預估 = 4308\n",
            "第17筆資料為數字:\t1489478\t|正確答案 = 5706\t模型預估 = 5724\n",
            "第18筆資料為數字:\t3728288\t|正確答案 = 12475\t模型預估 = 12639\n",
            "第19筆資料為數字:\t1401200\t|正確答案 = 7447\t模型預估 = 7268\n",
            "第20筆資料為數字:\t2226458\t|正確答案 = 9190\t模型預估 = 9413\n",
            "第21筆資料為數字:\t2073622\t|正確答案 = 8081\t模型預估 = 8198\n",
            "第22筆資料為數字:\t1299472\t|正確答案 = 5079\t模型預估 = 5120\n",
            "第23筆資料為數字:\t1144388\t|正確答案 = 5706\t模型預估 = 5462\n",
            "第24筆資料為數字:\t2720228\t|正確答案 = 11304\t模型預估 = 11380\n",
            "第25筆資料為數字:\t2743852\t|正確答案 = 9534\t模型預估 = 9758\n",
            "第26筆資料為數字:\t1369542\t|正確答案 = 10458\t模型預估 = 10649\n",
            "第27筆資料為數字:\t357142\t|正確答案 = 1749\t模型預估 = 1721\n",
            "第28筆資料為數字:\t2464432\t|正確答案 = 8683\t模型預估 = 8894\n",
            "第29筆資料為數字:\t3457034\t|正確答案 = 14019\t模型預估 = 14183\n",
            "第30筆資料為數字:\t3999548\t|正確答案 = 15744\t模型預估 = 15918\n",
            "第31筆資料為數字:\t2534456\t|正確答案 = 9222\t模型預估 = 9050\n",
            "第32筆資料為數字:\t1795496\t|正確答案 = 6730\t模型預估 = 6831\n",
            "第33筆資料為數字:\t2494648\t|正確答案 = 10344\t模型預估 = 10356\n",
            "第34筆資料為數字:\t398730\t|正確答案 = 4979\t模型預估 = 5075\n",
            "第35筆資料為數字:\t1295722\t|正確答案 = 5024\t模型預估 = 5117\n",
            "第36筆資料為數字:\t2624800\t|正確答案 = 13112\t模型預估 = 13156\n",
            "第37筆資料為數字:\t1634822\t|正確答案 = 7834\t模型預估 = 7876\n",
            "第38筆資料為數字:\t3523762\t|正確答案 = 13176\t模型預估 = 13549\n",
            "第39筆資料為數字:\t3300936\t|正確答案 = 22661\t模型預估 = 22532\n",
            "第40筆資料為數字:\t1140072\t|正確答案 = 9125\t模型預估 = 9161\n",
            "第41筆資料為數字:\t681956\t|正確答案 = 3256\t模型預估 = 3380\n",
            "第42筆資料為數字:\t1973266\t|正確答案 = 7219\t模型預估 = 7372\n",
            "第43筆資料為數字:\t1557572\t|正確答案 = 5899\t模型預估 = 5955\n",
            "第44筆資料為數字:\t1461278\t|正確答案 = 7745\t模型預估 = 7390\n",
            "第45筆資料為數字:\t3436188\t|正確答案 = 29406\t模型預估 = 29989\n",
            "第46筆資料為數字:\t1878790\t|正確答案 = 9390\t模型預估 = 9410\n",
            "第47筆資料為數字:\t1952342\t|正確答案 = 8752\t模型預估 = 8692\n",
            "第48筆資料為數字:\t1266936\t|正確答案 = 11062\t模型預估 = 11142\n",
            "第49筆資料為數字:\t1487036\t|正確答案 = 5862\t模型預估 = 5830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-1db06758a734>:3: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print (f\"第{index}筆資料為數字:\\t{number}\\t|正確答案 = {testDataPartition[index]}\\t模型預估 = {int(normalizedPred[index])}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"\\t正確答案  \"  , \"\\t/\" ,\"  \\t模型預測\")\n",
        "for index, number in enumerate(testDataNumbers):\n",
        "  print (f\"{index}\\t{testDataLabel[index]}  \\t\\t/  \\t{roundPredictions[index]} = {testDataLabel[index]/roundPredictions[index]} \")\n",
        "print (\"###########################################################################\")\n",
        "\n",
        "print (\"\\t正確答案  \"  , \"\\t-\" ,\"  \\t模型預測\")\n",
        "for index, number in enumerate(testDataNumbers):\n",
        "  print (f\"{index}\\t{testDataLabel[index]}  \\t\\t-  \\t{roundPredictions[index]} = {testDataLabel[index]-roundPredictions[index]} \")"
      ],
      "metadata": {
        "id": "U88QnsT5L0ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#正確答案 = {testDataPartition[index]}\\t模型預估 = {int(normalizedPred[index])}\")\n",
        "D = []\n",
        "for index in range (len(testDataPartition)):\n",
        "  D.append(testDataPartition[index] - int(normalizedPred[index]))\n",
        "\n",
        "\n",
        "print (\"\\t正確答案  \"  , \"\\t-\" ,\"  \\t模型預測\\t\\t差距量\")\n",
        "for index, number in enumerate(testDataNumbers):\n",
        "  print (f\"{index}\\t{testDataPartition[index]}\\t\\t\\t{int(normalizedPred[index])}\\t=\\t{abs(D[index])}\")"
      ],
      "metadata": {
        "id": "48aQwcS1L_Di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for num in D:\n",
        "#   print (abs(num))"
      ],
      "metadata": {
        "id": "fdY9KjD1kHkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RMSE and error rate"
      ],
      "metadata": {
        "id": "xdnoA-2U3Jy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mse(predictions, targets):\n",
        "    \"\"\"\n",
        "    計算均方誤差 (MSE)\n",
        "\n",
        "    參數:\n",
        "    predictions: 預測值的列表或陣列\n",
        "    targets: 實際值的列表或陣列，與預測值對應\n",
        "\n",
        "    返回值:\n",
        "    mse: 均方誤差\n",
        "    \"\"\"\n",
        "    # 確保預測值和實際值的長度相等\n",
        "    if len(predictions) != len(targets):\n",
        "        raise ValueError(\"預測值和實際值的長度不一致\")\n",
        "\n",
        "    # 計算平方誤差\n",
        "    squared_errors = [(p - t) ** 2 for p, t in zip(predictions, targets)]\n",
        "\n",
        "    # 計算均方誤差\n",
        "    mse = sum(squared_errors) / len(predictions)\n",
        "\n",
        "    return mse\n",
        "\n",
        "# 使用 LN\n",
        "mse_result = calculate_mse(normalizedPred, testDataPartition)\n",
        "\n",
        "# 使用 MLP(old)\n",
        "#mse_result = calculate_mse(predictions, testDataPartition)\n",
        "\n",
        "print(\"均方誤差 (MSE):\", mse_result)\n"
      ],
      "metadata": {
        "id": "INctEhXo3peo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c58bdf0a-120e-44d7-dd01-c2b2e12fe434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "均方誤差 (MSE): [38138.887]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fGBhCVtTk7H6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = testData['Partition'].mean()\n",
        "\n",
        "#LN MSE\n",
        "MSE = int(calculate_mse(normalizedPred, testDataPartition))\n",
        "\n",
        "#MLP MSE\n",
        "# MSE = int(calculate_mse(predictions, testDataPartition))\n",
        "\n",
        "RMSE= math.sqrt(MSE)\n",
        "errorRate = RMSE/mean\n",
        "\n",
        "print (f\"MSE : {MSE}\\nRMSE : {RMSE}\\nError Rate : {errorRate}  ->  {round(errorRate,7)*100}%\")"
      ],
      "metadata": {
        "id": "JqxlmzVbuYrJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c76c8d08-25c5-495f-9f75-90002b51c09b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE : 38138\n",
            "RMSE : 195.28952864913163\n",
            "Error Rate : 0.01911043435259141  ->  1.9110399999999998%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-5f40d6fac6f7>:4: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  MSE = int(calculate_mse(normalizedPred, testDataPartition))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## calculate compare"
      ],
      "metadata": {
        "id": "CR4NsRMX9WV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# G4 列表\n",
        "g4_data = [\n",
        "    12306.97217, 10763.92655, 11047.61962, 13718.37828, 16503.7549,\n",
        "    16038.78061, 6888.485915, 11894.65019, 10896.95969, 12899.55966,\n",
        "    10441.55882, 14573.09294, 7306.332787, 5688.120591, 10025.57947,\n",
        "    14106.70248, 5521.838135, 8147.605931, 17884.49069, 7734.457538,\n",
        "    11485.84299, 10807.51713, 7253.944225, 6511.296805, 13637.86933,\n",
        "    13739.47874, 7585.445277, 2442.257115, 12530.05337, 16758.18477,\n",
        "    19000.42027, 12834.74692, 9555.617669, 12661.66832, 2677.647078,\n",
        "    7236.135417, 13226.24286, 8820.750395, 17036.26899, 16104.9424,\n",
        "    6490.43907, 4201.908539, 10358.53232, 8464.027376, 8015.997274,\n",
        "    16671.17028, 9933.079275, 10264.54316, 7099.194388, 8136.222586\n",
        "]\n",
        "\n",
        "# Partition 列表\n",
        "partition_data = [\n",
        "    8617, 19867, 8004, 10361, 23485, 12582, 10215, 17107, 7593, 9229,\n",
        "    7271, 10311, 6145, 4055, 7413, 28467, 4255, 5706, 12475, 7447,\n",
        "    9190, 8081, 5079, 5706, 11304, 9534, 10458, 1749, 8683, 14019,\n",
        "    15744, 9222, 6730, 10344, 4979, 5024, 13112, 7834, 13176, 22661,\n",
        "    9125, 3256, 7219, 5899, 7745, 29406, 9390, 8752, 11062, 5862\n",
        "]\n",
        "\n",
        "\n",
        "# data = [16566, 31717, 14594, 14832, 15673, 16346, 13108, 18098, 31284, 42050, 15623, 15886, 28364, 14047, 14997, 22961, 16070, 13302, 13996, 15871, 15845, 32717, 31204, 19410, 30918, 23276, 15798, 31307, 20215, 17037, 26490, 14456, 17861, 17657, 15340, 18648, 16372, 34817, 13763, 34670, 19071, 29963, 15154, 30274, 28296, 14357, 14977, 18535, 27127, 20936]\n",
        "# Y = data\n",
        "\n",
        "# data_G4 = [19959.77789, 19043.70527, 20192.60057, 19619.70493, 22696.4686, 21574.48907, 19045.11374, 21699.99089, 22538.3116, 22509.83347, 22120.12068, 21240.16567, 20326.67296, 20251.18902, 21669.83672, 22832.38546, 21528.54568, 19154.0269, 20081.63799, 19080.38587, 22729.65287, 21282.0421, 20075.35702, 20943.54237, 22309.57154, 22520.30163, 20152.6507, 22540.06135, 21866.0713, 19879.94198, 19099.09062, 20105.27236, 22373.46703, 19197.65336, 21991.31311, 21653.58805, 19698.68447, 20080.01293, 19680.65124, 22846.63572, 22202.19255, 21457.14545, 21858.58381, 20675.0703, 20419.95711, 20788.33579, 21550.50989, 22194.6816, 19650.14487, 22721.41732]\n",
        "# G4 = data_G4\n",
        "\n",
        "# data = [\n",
        "#     41873, 15970, 36998, 16630, 41419, 16170, 36489, 46016, 21873, 46833,\n",
        "#     24297, 18243, 20365, 35177, 20254, 16261, 16516, 17868, 51232, 47532,\n",
        "#     18281, 24484, 38850, 22417, 34193, 16924, 18225, 40536, 43083, 18047,\n",
        "#     26526, 18284, 35358, 36243, 19891, 18273, 18872, 16884, 21970, 18317,\n",
        "#     21718, 33465, 16123, 16532, 32749, 59999, 25988, 17537, 17005, 46055\n",
        "# ]\n",
        "\n",
        "\n",
        "# data_G4 = [\n",
        "#     25229.18863, 23054.15175, 26722.64269, 23835.95233, 26247.90106,\n",
        "#     23151.84334, 26268.20655, 24954.14488, 26579.59727, 26389.03171,\n",
        "#     25960.91309, 25967.55943, 26374.33224, 25472.36608, 24333.54365,\n",
        "#     23460.68793, 23617.82988, 25390.8572, 26762.32906, 25375.47929,\n",
        "#     24087.69113, 24771.50964, 23327.19795, 24150.18672, 23944.81831,\n",
        "#     24381.84798, 24872.552, 26383.5254, 25867.54114, 25424.35725,\n",
        "#     26170.15978, 25639.12247, 25451.47618, 25883.54246, 25625.28761,\n",
        "#     26353.25729, 24555.51608, 23786.99037, 23820.59235, 26035.44141,\n",
        "#     24111.96741, 24000.66944, 23183.25341, 23892.36305, 23438.92127,\n",
        "#     26681.4039, 25428.99776, 23134.38886, 23625.46399, 24170.43602\n",
        "# ]\n",
        "\n",
        "# # G4 列表\n",
        "# data = [\n",
        "#     30582.87895, 28254.67602, 30779.91057, 29544.02103, 29884.46132,\n",
        "#     27175.85977, 28656.286, 27580.47678, 27974.90818, 29539.97837,\n",
        "#     30693.76277, 27482.21143, 29473.27854, 28413.85728, 30270.75728,\n",
        "#     28134.31437, 28765.34852, 30554.06677, 29562.15822, 28413.82636,\n",
        "#     30027.40146, 28375.44399, 30727.86066, 27146.52851, 29791.39657,\n",
        "#     29695.26469, 29461.58446, 27369.92667, 27004.86417, 30008.71389,\n",
        "#     27220.88625, 27377.96029, 30459.0978, 29327.84368, 27615.05727,\n",
        "#     27746.74193, 27491.59142, 30045.41267, 30762.09074, 27040.28824,\n",
        "#     30196.18223, 29532.55381, 30624.84745, 27616.09708, 30105.66893,\n",
        "#     29775.09103, 29021.97298, 29846.00783, 28854.21881, 30041.17262\n",
        "# ]\n",
        "\n",
        "# # Partition 列表\n",
        "# data_G4 = [\n",
        "#     21247, 52497, 42538, 56567, 20655, 39674, 20618, 19672, 19776, 24851,\n",
        "#     30866, 19145, 20381, 39672, 42856, 23547, 26713, 43392, 29272, 28543,\n",
        "#     43559, 19590, 21548, 38724, 24732, 46592, 21568, 19175, 20544, 27743,\n",
        "#     37742, 20150, 23361, 50096, 39452, 19807, 41416, 51226, 29715, 22527,\n",
        "#     41906, 25002, 44874, 19909, 41788, 20557, 26829, 52046, 20804, 26579\n",
        "# ]\n",
        "\n",
        "# G4 列表\n",
        "# data_G4 = [\n",
        "#     30582.87895, 28254.67602, 30779.91057, 29544.02103, 29884.46132,\n",
        "#     27175.85977, 28656.286, 27580.47678, 27974.90818, 29539.97837,\n",
        "#     30693.76277, 27482.21143, 29473.27854, 28413.85728, 30270.75728,\n",
        "#     28134.31437, 28765.34852, 30554.06677, 29562.15822, 28413.82636,\n",
        "#     30027.40146, 28375.44399, 30727.86066, 27146.52851, 29791.39657,\n",
        "#     29695.26469, 29461.58446, 27369.92667, 27004.86417, 30008.71389,\n",
        "#     27220.88625, 27377.96029, 30459.0978, 29327.84368, 27615.05727,\n",
        "#     27746.74193, 27491.59142, 30045.41267, 30762.09074, 27040.28824,\n",
        "#     30196.18223, 29532.55381, 30624.84745, 27616.09708, 30105.66893,\n",
        "#     29775.09103, 29021.97298, 29846.00783, 28854.21881, 30041.17262\n",
        "# ]\n",
        "\n",
        "# # Partition 列表\n",
        "# data = [\n",
        "#     21247, 52497, 42538, 56567, 20655, 39674, 20618, 19672, 19776, 24851,\n",
        "#     30866, 19145, 20381, 39672, 42856, 23547, 26713, 43392, 29272, 28543,\n",
        "#     43559, 19590, 21548, 38724, 24732, 46592, 21568, 19175, 20544, 27743,\n",
        "#     37742, 20150, 23361, 50096, 39452, 19807, 41416, 51226, 29715, 22527,\n",
        "#     41906, 25002, 44874, 19909, 41788, 20557, 26829, 52046, 20804, 26579\n",
        "# ]\n",
        "\n",
        "\n",
        "\n",
        "print (\"G4 calculate:\\n\")\n",
        "mean = testData['Partition'].mean()\n",
        "MSE = int(calculate_mse(data_G4, data))\n",
        "RMSE= math.sqrt(MSE)\n",
        "errorRate = RMSE/mean\n",
        "\n",
        "print (f\"MSE : {MSE}\\nRMSE : {RMSE}\\nError Rate : {errorRate}  ->  {round(errorRate,7)*100}%\")"
      ],
      "metadata": {
        "id": "gXVYz2I6_kDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# generate GoldBach Partition"
      ],
      "metadata": {
        "id": "RnUbZEGRNZpu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lYAdL2HsUF-h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}